LMS算法是第一个视同神经网络模型完成回归任务的算法，模型利用矩阵表示y=w^T*x

LMS算法使用随机梯度下降法求解参数

LMS算法流程：

​	训练样本：输入信号向量=x(i) 期望响应=d(i) 

​	学习率：n

​	计算：当i=1,2...计算 aJ/aw = -x(i)e(i)  w(i+1)=w(i)+nx(i)e(i)

向前传播时，参数确定，x为变量，计算模型代价更新参数时，输入样本值确定，参数w是变量

最速下降法，也被称为梯度下降法

使用整个训练集的优化算法被称为批量算法或确定性算法

小批量算法是指使用小批量训练集的优化算法

每次只是用单个样本的优化算法被称为随机或在线算法

在线算法通常是指从连续生产样本的数据流中抽取样本的情况

随机算法通常是指从固定大小的训练集中便利多次采样的情况

动量方法，自适应学习率法等称为一阶优化法，牛顿法，拟牛顿法等成为二阶优化法	

LMS实现